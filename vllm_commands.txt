Phase 2 (Combined Image) quick commands

Build local image (amd64):
  TARGET_PLATFORM=linux/amd64 ./scripts/build_combined_image.sh

Build and push to Docker Hub:
  IMAGE_REPO=docker.io/<dockerhub-user>/vllm-combined IMAGE_TAG=phase2 PUSH=1 TARGET_PLATFORM=linux/amd64 ./scripts/build_combined_image.sh

Tag/push existing local image manually:
  docker tag vllm-combined:phase2 docker.io/<dockerhub-user>/vllm-combined:phase2
  docker push docker.io/<dockerhub-user>/vllm-combined:phase2

Run locally (GPU host):
  docker run --rm -it --gpus all -p 8000:8000 \
    -v model_cache:/cache \
    -v controlplane_data:/data \
    -e MODEL_ID=Qwen/Qwen2.5-3B-Instruct \
    -e ADMIN_TOKEN=$(openssl rand -hex 32) \
    -e BUILD_SHA=$(git rev-parse --short HEAD 2>/dev/null || echo dev) \
    -e BUILD_TIME=$(date -u +"%Y-%m-%dT%H:%M:%SZ") \
    vllm-combined:phase2

Health/version checks:
  curl -sS http://localhost:8000/livez
  curl -sS http://localhost:8000/healthz
  curl -sS http://localhost:8000/version

Acceptance smoke test (includes admin header rejection checks):
  ADMIN_TOKEN=<admin-token> BASE_URL=http://localhost:8000 ./scripts/phase2_smoke.sh

Admin-unavailable mode (run against deployment started without ADMIN_TOKEN):
  EXPECT_ADMIN_UNAVAILABLE=1 BASE_URL=http://localhost:8000 ./scripts/phase2_smoke.sh

Create tenant:
  ADMIN_TOKEN=<admin-token> BASE_URL=http://localhost:8000 ./scripts/create_tenant.sh tenant-a

List tenants:
  curl -sS http://localhost:8000/admin/tenants -H "X-Admin-Token: <admin-token>"

Set tenant limits (by tenant id or name):
  ADMIN_TOKEN=<admin-token> BASE_URL=http://localhost:8000 ./scripts/set_tenant_limits.sh tenant-a standard

Set tenant limits with overrides:
  MAX_CONCURRENT=3 RPM_LIMIT=240 TPM_LIMIT=180000 \
  ADMIN_TOKEN=<admin-token> BASE_URL=http://localhost:8000 \
  ./scripts/set_tenant_limits.sh tenant-a standard

Tenant inference call:
  curl -sS http://localhost:8000/v1/chat/completions \
    -H "Authorization: Bearer <tenant-api-key>" \
    -H "Content-Type: application/json" \
    -d '{"model":"ignored","messages":[{"role":"user","content":"hello"}],"max_tokens":64}'

Usage rollup:
  curl -sS "http://localhost:8000/admin/usage?window=1h" -H "X-Admin-Token: <admin-token>"
  curl -sS "http://localhost:8000/admin/usage?window=24h" -H "X-Admin-Token: <admin-token>"
  curl -sS "http://localhost:8000/admin/usage?window=7d" -H "X-Admin-Token: <admin-token>"

Metrics endpoint checks:
  # Missing header => 401 unauthorized
  curl -i http://localhost:8000/metrics
  # Correct header => Prometheus text format
  curl -sS -H "X-Admin-Token: <admin-token>" http://localhost:8000/metrics | head

Observe key metrics:
  curl -sS -H "X-Admin-Token: <admin-token>" http://localhost:8000/metrics \
    | rg "gateway_http_requests_total|gateway_rejections_total|gateway_engine_healthy|^gpu_"

Admin auth rejection checks:
  # Missing header => 401 unauthorized
  curl -i http://localhost:8000/admin/tenants
  # Wrong token => 401 unauthorized
  curl -i http://localhost:8000/admin/tenants -H "X-Admin-Token: wrong-token"

Runpod steps (single image):
  1) Push image tag: docker.io/<dockerhub-user>/vllm-combined:phase2
  2) Create GPU pod with image above
  3) Expose port 8000
  4) Set env vars at least: MODEL_ID, ADMIN_TOKEN
  5) Recommended envs:
     DB_PATH=/workspace/data/controlplane.db
     HF_HOME=/workspace/cache/huggingface
     HUGGINGFACE_HUB_CACHE=/workspace/cache/huggingface/hub
     TRANSFORMERS_CACHE=/workspace/cache/huggingface/transformers
     VLLM_CACHE_ROOT=/workspace/cache/vllm
  6) Use Runpod proxy URL as BASE_URL, then run:
     ADMIN_TOKEN=<admin-token> BASE_URL=<runpod-url> ./scripts/phase2_smoke.sh

Monitoring pack (outside Runpod container):
  1) Update monitoring/prometheus/prometheus.yml:
     - set target host (Runpod proxy host only, no https://)
     - set X-Admin-Token header value
  2) Start stack:
     docker compose -f monitoring/compose.yaml up -d --build
  3) Open:
     Prometheus: http://localhost:9090
     Grafana: http://localhost:3000 (admin/admin)
  4) Dashboard auto-provisioned:
     vLLM Control Plane Observability
